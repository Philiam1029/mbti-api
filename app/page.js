export default function Home() {
  return (
    <main style={{ padding: '2rem', fontFamily: 'system-ui' }}>
      <h1>âœ… MBTI API ä¸­ä»‹å±¤</h1>
      <p>API å·²å•Ÿå‹•ä¸¦æ­£åœ¨é‹è¡Œã€‚</p>
      
      <h2>ğŸ“ å¯ç”¨ç«¯é»</h2>
      <pre style={{ background: '#f5f5f5', padding: '1rem', borderRadius: '4px' }}>
{`POST /api/analyze
Content-Type: application/json

è«‹æ±‚æ ¼å¼ï¼š
{
  "text": "è¦åˆ†æçš„æ–‡å­—",
  "mbti": "INTJ",
  "locale": "zh-TW",
  "context": "general",
  "source": "chrome_extension"
}

å›æ‡‰æ ¼å¼ï¼š
{
  "literal": "å­—é¢æ„æ€",
  "signals": [{"cue": "ä¿¡è™Ÿ", "evidence": "è­‰æ“š"}],
  "mbti_lens": {
    "focus": ["é‡é»"],
    "likely_intentions": ["æ„åœ–"],
    "unspoken_needs": ["éœ€æ±‚"]
  },
  "misunderstanding_risks": [{"risk": "é¢¨éšª", "why": "åŸå› "}],
  "summary": "æ‘˜è¦"
}`}
      </pre>

      <h2>ğŸ”§ é…ç½®èªªæ˜</h2>
      <ul>
        <li><strong>LLM_PROVIDER</strong>: 'mock' (é»˜èª) | 'openai' | 'anthropic'</li>
        <li><strong>LLM_API_KEY</strong>: æ‚¨çš„ API é‡‘é‘°</li>
        <li><strong>LLM_MODEL</strong>: ä½¿ç”¨çš„æ¨¡å‹ (ä¾‹å¦‚ 'gpt-3.5-turbo')</li>
      </ul>

      <h2>ğŸš€ éƒ¨ç½²æ­¥é©Ÿ</h2>
      <ol>
        <li>æ¨é€æ­¤é …ç›®åˆ° GitHub</li>
        <li>ç™»å…¥ Vercel (vercel.com)</li>
        <li>é»æ“Šã€ŒNew Projectã€ä¸¦é¸æ“‡æ­¤ repo</li>
        <li>åœ¨ç’°å¢ƒè®Šæ•¸ä¸­è¨­å®š LLM_API_KEY</li>
        <li>é»æ“Šã€ŒDeployã€</li>
      </ol>

      <h2>ğŸ“š æ”¯æ´çš„æ¨¡å‹</h2>
      <h3>OpenAI</h3>
      <ul>
        <li>gpt-4 (æœ€ä½³è³ªé‡ï¼Œæˆæœ¬è¼ƒé«˜)</li>
        <li>gpt-3.5-turbo (å¹³è¡¡é¸é …)</li>
      </ul>
      <h3>Anthropic</h3>
      <ul>
        <li>claude-3-opus-20240229 (æœ€ä½³è³ªé‡)</li>
        <li>claude-3-sonnet-20240229 (æ¨è–¦)</li>
        <li>claude-3-haiku-20240307 (å¿«é€Ÿ)</li>
      </ul>
    </main>
  );
}
